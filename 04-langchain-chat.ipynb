{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvZxs0nFi_LI"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/04-langchain-chat.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/04-langchain-chat.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdwa2QfAp9pT",
        "outputId": "5a168276-60f7-41f9-9fc2-e1f5d07d6989"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  langchain==0.3.25 \\\n",
        "  langchain-community==0.3.25 \\\n",
        "  langchain-openai==0.3.22 \\\n",
        "  jinja2==3.1.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnXqS4T_q5m4"
      },
      "source": [
        "We'll start by initializing the `ChatOpenAI` object. For this we'll need an [OpenAI API key](https://platform.openai.com/account/api-keys). Note that there is naturally a small cost to running this notebook due to the paid nature of OpenAI's API access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3xQHFXErQyv",
        "outputId": "b105e220-4260-4261-ab85-6d9b9fdb61d3"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# must enter API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \\\n",
        "    or getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "# below should not be changed\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "# you can change this as preferred\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-pinecone-io-walkthrough-chat\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zKBICpJsNqp"
      },
      "source": [
        "Initialize the `ChatOpenAI` object. We'll set `temperature=0` to minimize randomness and make outputs repeatable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1i7tIsh2rX8Q"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the chat model\n",
        "chat = ChatOpenAI(\n",
        "    temperature=1.0,\n",
        "    model='gpt-5-mini'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRZFsmH_t3K5"
      },
      "source": [
        "Chats with the Chat-GPT model `gpt-4.1-mini` are typically structured like so:\n",
        "\n",
        "```\n",
        "System: You are a helpful assistant.\n",
        "\n",
        "User: Hi AI, how are you today?\n",
        "\n",
        "Assistant: I'm great thank you. How can I help you?\n",
        "\n",
        "User: I'd like to understand string theory.\n",
        "```\n",
        "\n",
        "The final `\"Assistant:\"` without a response is what would prompt the model to continue the conversation. In the official OpenAI `ChatCompletion` endpoint these would be passed to the model in a format like:\n",
        "\n",
        "```json\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hi AI, how are you today?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I'm great thank you. How can I help you?\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'd like to understand string theory.\"}\n",
        "]\n",
        "```\n",
        "\n",
        "In LangChain there is a slightly different format. We use three *message* objects like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqFLoaRqtl8z",
        "outputId": "a9945991-4be1-4ad1-a97d-a3117049196f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi — I'm doing well, thanks! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Create the message templates\n",
        "system_template = \"You are a helpful assistant.\"\n",
        "human_template = \"{input}\"\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template)\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = prompt | chat | StrOutputParser()\n",
        "\n",
        "# Test the chain\n",
        "result = chain.invoke({\"input\": \"Hi AI, how are you today?\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7AJh2ACytwc"
      },
      "source": [
        "The format is very similar, we're just swapping the role of `\"user\"` for `HumanMessage`, and the role of `\"assistant\"` for `AIMessage`.\n",
        "\n",
        "We generate the next response from the AI by passing these messages to the `ChatOpenAI` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKMcBaPR3AAv",
        "outputId": "f7110315-cd4a-4fc9-c25a-a007017312d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Great — I can explain at several levels. Before I start: what’s your background (high‑school physics, undergraduate physics, familiarity with quantum mechanics and general relativity, or mathematical physics)? That will let me tailor the level. Meanwhile, here’s a compact, clear overview plus a suggested learning path.\n",
            "\n",
            "Short, nontechnical summary\n",
            "- String theory replaces point particles with tiny one‑dimensional strings. Different vibrational modes of a string look like different particles (electrons, photons, gravitons).\n",
            "- Because strings have extent, some mathematical problems that make combining quantum mechanics and general relativity inconsistent for point particles are softened, and a spin‑2 vibration mode naturally behaves like a graviton — so string theory naturally includes gravity.\n",
            "- To be mathematically consistent, string theory needs extra spatial dimensions (usually 9 space + 1 time in superstring theory). Those extra dimensions are “compactified” (curled up) on very tiny shapes; the geometry determines low‑energy physics.\n",
            "- There are several consistent superstring theories and a conjectured 11‑dimensional unifying theory called M‑theory. Dualities relate these different descriptions.\n",
            "- Major open issues: connecting the theory uniquely to observed particle physics (many possible compactifications — the “landscape”) and finding direct experimental tests at accessible energies.\n",
            "\n",
            "Key concepts (one‑sentence each)\n",
            "- Strings: fundamental 1D objects with tension; can be open (ends) or closed (loops).\n",
            "- Modes: quantized vibrations of strings correspond to particles with different masses/spins.\n",
            "- String tension and length: characteristic scale usually near the Planck length (~1.6×10^-35 m).\n",
            "- Ghosts & anomalies: consistency requires certain dimensions and symmetries (leading to superstrings and extra dimensions).\n",
            "- Supersymmetry (SUSY): a symmetry between fermions and bosons needed in superstring theories for consistency.\n",
            "- Compactification: extra dimensions are shaped (e.g., Calabi–Yau manifolds) to give 4D physics.\n",
            "- Dualities: equivalences that relate weak coupling to strong coupling (S‑duality) or large to small compact dimensions (T‑duality).\n",
            "- M‑theory: proposed 11D framework that unifies the five consistent 10D superstring theories.\n",
            "- AdS/CFT: a precise duality that relates some string theories in curved spacetime (AdS) to quantum field theories without gravity — a powerful tool for calculations.\n",
            "\n",
            "Why people study it\n",
            "- Candidate for a quantum theory of gravity that could unify all forces.\n",
            "- Rich mathematical structure with applications across mathematics and theoretical physics (e.g., mirror symmetry, topology).\n",
            "- Tools like AdS/CFT have applications beyond high‑energy theory (condensed matter, nuclear physics).\n",
            "\n",
            "Main challenges and criticisms\n",
            "- Very high characteristic energy (near Planck scale) makes direct experimental tests extremely difficult.\n",
            "- Landscape of many solutions — hard to pick the one that matches our universe.\n",
            "- Supersymmetry, if required and low‑energy, hasn’t been observed at LHC energies (so far).\n",
            "\n",
            "If you want to study it seriously: prerequisites and a learning path\n",
            "- Prerequisites: undergraduate quantum mechanics, special relativity, classical mechanics, electromagnetism, and ideally quantum field theory and general relativity.\n",
            "- Beginner pathway (months to a year depending on background):\n",
            "  1. Learn quantum mechanics and special relativity well.\n",
            "  2. Study introductory quantum field theory (free fields, quantization, Feynman diagrams).\n",
            "  3. Learn basic general relativity (differential geometry, curvature, Einstein equations).\n",
            "  4. Read an introductory string text: Zwiebach, A First Course in String Theory — friendly and conceptual.\n",
            "  5. Move to more advanced texts: Polchinski (two volumes) or Becker–Becker–Schwarz.\n",
            "  6. Study supersymmetry and supergravity as needed.\n",
            "  7. Dive into compactification, Calabi–Yau geometry, and advanced topics like dualities and AdS/CFT.\n",
            "\n",
            "Recommended resources\n",
            "- Intro: Barton Zwiebach, \"A First Course in String Theory\" (student friendly).\n",
            "- Advanced: Joseph Polchinski, \"String Theory\" Vol. 1 & 2.\n",
            "- Reviews/lectures: David Tong’s lecture notes (string theory, quantum field theory) — clear and freely available online.\n",
            "- Popular-level: Brian Greene, \"The Elegant Universe\" (for conceptual understanding).\n",
            "\n",
            "How I can help next\n",
            "- Give a plain-English analogy and short animations of how modes become particles.\n",
            "- Walk through a single technical derivation (e.g., how the quantized closed string has a spin‑2 state).\n",
            "- Create a tailored study plan given your background and time.\n",
            "- Explain a particular concept in more depth (compactification, AdS/CFT, dualities, supersymmetry).\n",
            "\n",
            "Tell me your background and which of the above you'd like next, and I’ll continue at that level.\n"
          ]
        }
      ],
      "source": [
        "# Create initial messages\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant.\"),\n",
        "    (\"human\", \"Hi AI, how are you today?\"),\n",
        "    (\"ai\", \"I'm great thank you. How can I help you?\"),\n",
        "    (\"human\", \"I'd like to understand string theory.\")\n",
        "])\n",
        "\n",
        "# Create the chain using LCEL pipe syntax\n",
        "chain = prompt | chat | StrOutputParser()\n",
        "\n",
        "# Get response using LCEL\n",
        "res = chain.invoke({})\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STl7g3PQ3kg8"
      },
      "source": [
        "Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "ESZ6UrBA4PwZ",
        "outputId": "5d6e5a9e-91f0-403b-88fb-2bcad1dacd0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Short answer\\nPhysicists consider string theory a promising candidate for a unified theory because it naturally contains both gravity and the other forces in the same framework, it replaces the problematic point‑particle picture that makes quantum gravity nonrenormalizable, and it passes several nontrivial consistency checks that no arbitrary theory would.\\n\\nWhy that is — the core reasons\\n\\n- Gravity comes out automatically.\\n  - The quantum excitations of a closed string include a massless spin‑2 state. In low‑energy effective field theory this state has the same couplings as the graviton of general relativity, so Einstein’s equations arise as the low‑energy dynamics of string theory.\\n\\n- Point‑particle short‑distance problems are softened.\\n  - A string has finite size, so interactions are “smeared out” over the string scale. That changes high‑energy behavior of scattering amplitudes and removes many of the ultraviolet divergences that plague point‑particle quantum gravity. Perturbative string amplitudes are much better behaved than those of quantum field theory.\\n\\n- One object → many particle types.\\n  - Different vibrational modes of a single fundamental string look like different particles (different masses, spins, quantum numbers). Thus matter and force carriers are unified as excitations of the same basic object rather than being put in by hand.\\n\\n- Gauge forces fit naturally.\\n  - Gauge bosons arise from open strings (or from internal degrees of freedom in heterotic strings). Specific, nontrivial gauge groups (e.g. SO(32), E8×E8 for the heterotic string) appear as required for consistency.\\n\\n- Consistency forces structure (not arbitrary choices).\\n  - String consistency conditions (absence of anomalies, modular invariance, etc.) force the theory into narrow possibilities: certain spacetime dimensions, supersymmetry, and particular gauge groups. The Green–Schwarz anomaly cancellation is a famous example — a highly nontrivial check that fixed allowed gauge groups.\\n\\n- Dualities point to a single underlying framework.\\n  - Different string theories are related by S‑ and T‑dualities and are believed to be different limits of a deeper 11‑dimensional M‑theory. That web of relations suggests a unique, unified underlying theory rather than many disconnected models.\\n\\nSupporting nontrivial successes (evidence that it’s more than hand waving)\\n- Black hole entropy: for certain supersymmetric black holes, string theory correctly reproduces the Bekenstein–Hawking entropy by counting microstates (Strominger–Vafa result).\\n- AdS/CFT duality: in some cases string theory on a curved spacetime is exactly dual to a nongravitational quantum field theory. This gives a concrete, nonperturbative realization of gravity emerging from a field theory and has been checked in many ways.\\n- Mathematical predictions and structures (mirror symmetry, new geometry) that were later confirmed or found rich applications in mathematics.\\n\\nImportant caveats and open problems\\n- Landscape and predictivity: compactifying extra dimensions gives an enormous number of low‑energy effective theories (“vacua”), so extracting a unique prediction for the Standard Model is hard.\\n- Experimental tests: the characteristic string scale is usually near the Planck scale, far beyond current experiments. Supersymmetry, if required at accessible energies, has not yet been observed.\\n- Nonperturbative formulation incomplete: while AdS/CFT gives a nonperturbative definition in special cases, a fully general nonperturbative definition of string/M‑theory in realistic cosmological spacetimes is still lacking.\\n\\nIf you want to go deeper\\nI can:\\n- Sketch how the quantized closed string yields a spin‑2 graviton.\\n- Explain the Green–Schwarz anomaly cancellation in simple terms.\\n- Show how compactification can produce gauge groups and chiral fermions (and why that leads to the landscape).\\nTell me your background (physics/math level) and which of those you want and I’ll go into the appropriate level of detail.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For the follow-up question, we can extend the existing prompt\n",
        "prompt.extend([\n",
        "    (\"ai\", res),  # Previous AI response\n",
        "    (\"human\", \"Why do physicists believe it can produce a 'unified theory'?\")\n",
        "])\n",
        "\n",
        "# Create the chain using LCEL pipe syntax\n",
        "chain = prompt | chat | StrOutputParser()\n",
        "\n",
        "# Get response\n",
        "result = chain.invoke({})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jfnGuEK5suC"
      },
      "source": [
        "## New Prompt Templates\n",
        "\n",
        "Alongside what we've seen so far there are also three new prompt templates that we can use. Those are the `SystemMessagePromptTemplate`, `AIMessagePromptTemplate`, and `HumanMessagePromptTemplate`.\n",
        "\n",
        "These are simply an extension of [Langchain's prompt templates](https://www.pinecone.io/learn/series/langchain/langchain-prompt-templates/) that modify the returning \"prompt\" to be a `SystemMessage`, `AIMessage`, or `HumanMessage` object respectively.\n",
        "\n",
        "For now, there are not a huge number of use-cases for these objects. However, they can be useful if:\n",
        "- You want different types of response; AND\n",
        "- The types of response should depend on a set of pre-determined input values; AND\n",
        "- You want to save tokens by not explicitly specifying every possible type of input value in the prompts.\n",
        "\n",
        "This will make more sense with an example. Suppose you want to tailor responses to people from a wide variety of countries. E.g. an LLM powered worldwide translator!\n",
        "\n",
        "Some of the languages listed have been commented out as this is just an illustrative example, but the idea is that we can have many languages and dynamically alter the `HumanMessage` prompt so that we don't have to list all of them every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nuZ2f7wci_LK"
      },
      "outputs": [],
      "source": [
        "languages = [\n",
        "    \"English\",\n",
        "    \"Esperanto\",\n",
        "    \"Spanish\",\n",
        "    # \"French\",\n",
        "    # \"German\",\n",
        "    # \"Italian\",\n",
        "    # \"Portuguese\",\n",
        "    # \"Dutch\",\n",
        "    # \"Russian\",\n",
        "    # \"Chinese (Simplified)\",\n",
        "    # \"Chinese (Traditional)\",\n",
        "    # \"Japanese\",\n",
        "    # \"Korean\",\n",
        "    # \"Arabic\",\n",
        "    # \"Hindi\",\n",
        "    # \"Turkish\",\n",
        "    # \"Swedish\",\n",
        "    # \"Danish\",\n",
        "    # \"Norwegian\",\n",
        "    # \"Finnish\",\n",
        "    # \"Polish\",\n",
        "    # \"Czech\",\n",
        "    # \"Hungarian\",\n",
        "    # \"Greek\",\n",
        "    # \"Hebrew\",\n",
        "    # \"Vietnamese\",\n",
        "    # \"Thai\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sto1isO-i_LK"
      },
      "source": [
        "First let's see what the prompt looks like with single example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m62JxYxqi_LK",
        "outputId": "9a865e15-2b5e-4d92-f959-4ab9e6178d20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Esperanto. Do not include any other text in your response.', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
        "\n",
        "# Create the prompt template\n",
        "human_template = HumanMessagePromptTemplate.from_template(\n",
        "    \"Translate this input <INPUT_START> {input} <INPUT_END>  into {language}. Do not include any other text in your response.\"\n",
        ")\n",
        "chat_prompt = ChatPromptTemplate.from_messages([human_template])\n",
        "\n",
        "# Format with dynamic input\n",
        "chat_prompt_value = chat_prompt.format_prompt(\n",
        "    input=\"I hope when you come the weather will be clement.\", # Extra points if you get the reference.\n",
        "    language=\"Esperanto\"\n",
        ")\n",
        "\n",
        "chat_prompt_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMpQ6dOxi_LK"
      },
      "source": [
        "Note that to use `HumanMessagePromptTemplate` as typical a prompt templates with the `.format_prompt` method, we needed to pass it through a `ChatPromptTemplate` object. This is case for all of the new chat-based prompt templates.\n",
        "\n",
        "Using this we return a `ChatPromptValue` object. This can be formatted into a list or string like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LCL-7wAi_LK",
        "outputId": "013f2e49-ef0c-44d2-dfa7-4b6238328b4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Esperanto. Do not include any other text in your response.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt_value.to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7-wYQKNmi_LK",
        "outputId": "7cb380ea-5c9b-42cd-ae1f-aca0a6716555"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Human: Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Esperanto. Do not include any other text in your response.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt_value.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsCQlnaYi_LK"
      },
      "source": [
        "Okay, let's see this new approach in action with our list of languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWPa7sGO4w_O",
        "outputId": "216a3d5c-3581-4547-a800-60a8c485f23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Response in English ===\n",
            "I hope that when you come, the weather will be clement.\n",
            "==================================================\n",
            "\n",
            "=== Response in Esperanto ===\n",
            "Mi esperas, ke kiam vi venos, la vetero estos milda.\n",
            "==================================================\n",
            "\n",
            "=== Response in Spanish ===\n",
            "Espero que cuando vengas haga buen tiempo.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
        "\n",
        "# Create the prompt template\n",
        "human_template = HumanMessagePromptTemplate.from_template(\n",
        "    \"Translate this input '{input}' into {language}. Do not include any other text in your response.\"\n",
        ")\n",
        "system_template = SystemMessagePromptTemplate.from_template(\"You are a helpful assistant.\")\n",
        "\n",
        "# Create the chain using LCEL pipe syntax\n",
        "chain = (\n",
        "    ChatPromptTemplate.from_messages([system_template, human_template])\n",
        "    | chat\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Loop through each language\n",
        "for language in languages:\n",
        "    print(f\"\\n=== Response in {language} ===\")\n",
        "\n",
        "    # Invoke the chain with our inputs\n",
        "    result = chain.invoke({\n",
        "        \"input\": \"I hope when you come the weather will be clement.\",\n",
        "        \"language\": language\n",
        "    })\n",
        "\n",
        "    print(result)\n",
        "    print(\"=\" * 50)  # Separator for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9riszRQri_LK"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "As you can see, it's successfully translated into different languages based on our inputs, *and we didn't have to use unnecessary tokens by inserting the entire language list into the prompt.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfLRjgjCFNUY"
      },
      "source": [
        "What if the outputs we need are more complicated? For example, what if the input information is technical information that needs to be formatted in a very specific way for the output?\n",
        "\n",
        "E.g. Say that we want to:\n",
        "1. Input technical information.\n",
        "2. Only translate part of the technical information, not all of the text.\n",
        "3. Maintain the same input structure in the output structure.\n",
        "\n",
        "We can use the prompt templates approach for building an initial system message with a few examples for the chatbot to follow — few-shot training via examples. Let's see what that looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M19Ji8gGCOwk",
        "outputId": "312b7d66-e709-46cd-8271-35f81680c128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Technical Translation in English ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Database connection failed',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: This error occurs when the application cannot connect to the database.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Esperanto ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Konekto al Database malsukcesis',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: Ĉi tiu eraro okazas kiam la aplikaĵo ne povas konekti al la database.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Spanish ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Conexión a la base de datos fallida',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: Este error ocurre cuando la aplicación no puede conectarse a la base de datos.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create few-shot examples for technical content formatting\n",
        "system_template = SystemMessagePromptTemplate.from_template(\n",
        "    \"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
        "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
        "\n",
        "    Example input and output pairs:\n",
        "\n",
        "    Input: \"Error 404: Page not found\"\n",
        "    Output: \"Error 404: Página no encontrada\"\n",
        "\n",
        "    Input: \"Status: 200 OK\n",
        "    Response: {{\n",
        "        'data': 'success',\n",
        "        'message': 'Operation completed'\n",
        "    }}\"\n",
        "    Output: \"Status: 200 OK\n",
        "    Response: {{\n",
        "        'data': 'success',\n",
        "        'message': 'Operación completada'\n",
        "    }}\"\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Example of a technical input\n",
        "human_template = HumanMessagePromptTemplate.from_template(\n",
        "    \"\"\"Translate this technical information to {language}:\n",
        "\n",
        "    Status: 500 Internal Server Error\n",
        "    Response: {{\n",
        "        'error': 'Database connection failed',\n",
        "        'code': 'DB_001',\n",
        "        'timestamp': '2024-03-20T10:30:00Z'\n",
        "    }}\n",
        "\n",
        "    Technical Note: This error occurs when the application cannot connect to the database.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create the chain using LCEL pipe syntax\n",
        "chain = (\n",
        "    ChatPromptTemplate.from_messages([system_template, human_template])\n",
        "    | chat\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Loop through each language\n",
        "for language in languages:\n",
        "    print(f\"\\n=== Technical Translation in {language} ===\")\n",
        "\n",
        "    # Invoke the chain with our input\n",
        "    result = chain.invoke({\"language\": language})\n",
        "\n",
        "    print(result)\n",
        "    print(\"=\" * 80)  # Separator for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jZTYOHvKb_B"
      },
      "source": [
        "Perfect, we seem to get a good response!\n",
        "\n",
        "Now, it's arguable as to whether all of the above is better than simple f-strings like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIZz2eewP3k4",
        "outputId": "898cadb4-7310-49f6-d5aa-3b16a56afe25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Technical Translation in English ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Database connection failed',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: This error occurs when the application cannot connect to the database.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Esperanto ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Konekto al datumbazo malsukcesis',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: Ĉi tiu eraro okazas kiam la aplikado ne povas konekti al la datumbazo.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Spanish ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {\n",
            "        'error': 'Fallo en la conexión a la base de datos',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }\n",
            "\n",
            "    Technical Note: Este error ocurre cuando la aplicación no puede conectarse a la base de datos.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "# Create the system message with examples\n",
        "system_message = SystemMessage(content=\"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
        "Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
        "\n",
        "Example input and output pairs:\n",
        "\n",
        "Input: \"Error 404: Page not found\"\n",
        "Output: \"Error 404: Página no encontrada\"\n",
        "\n",
        "Input: \"Status: 200 OK\n",
        "Response: {\n",
        "    'data': 'success',\n",
        "    'message': 'Operation completed'\n",
        "}\"\n",
        "Output: \"Status: 200 OK\n",
        "Response: {\n",
        "    'data': 'success',\n",
        "    'message': 'Operación completada'\n",
        "}\"\n",
        "\"\"\")\n",
        "\n",
        "# Loop through each language\n",
        "for language in languages:\n",
        "    print(f\"\\n=== Technical Translation in {language} ===\")\n",
        "\n",
        "    # Create the human message using f-string\n",
        "    human_message = HumanMessage(content=f\"\"\"Translate this technical information to {language}:\n",
        "\n",
        "    Status: 500 Internal Server Error\n",
        "    Response: {{\n",
        "        'error': 'Database connection failed',\n",
        "        'code': 'DB_001',\n",
        "        'timestamp': '2024-03-20T10:30:00Z'\n",
        "    }}\n",
        "\n",
        "    Technical Note: This error occurs when the application cannot connect to the database.\n",
        "    \"\"\")\n",
        "\n",
        "    # Create messages list\n",
        "    messages = [system_message, human_message]\n",
        "\n",
        "    # Get response\n",
        "    res = chat.invoke(messages)\n",
        "\n",
        "    print(res.content)\n",
        "    print(\"=\" * 80)  # Separator for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiDVIIkhQwWD"
      },
      "source": [
        "In this example, the above is far simpler. So we wouldn't necessarily recommend using prompt templates over f-strings in all scenarios.\n",
        "\n",
        "One example where Prompt Templates might prove useful is in interpreting specific template format types. For example, suppose a project uses lots of `jinja` templates. Rather than writing our functions that handle the input values, f-strings and which renders the jinja template, LangChain Prompt Templates do all of this for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWvyfhNQivT",
        "outputId": "25969dda-60b6-419e-92f1-2a3f5eca7e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Technical Translation in English ===\n",
            "Status: 500 Internal Server Error\n",
            "Response: {{\n",
            "    'error': 'Database connection failed',\n",
            "    'code': 'DB_001',\n",
            "    'timestamp': '2024-03-20T10:30:00Z'\n",
            "}}\n",
            "\n",
            "Technical Note: This error occurs when the application cannot connect to the database.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Esperanto ===\n",
            "Status: 500 Internal Server Error\n",
            "Response: {{\n",
            "    'error': 'Konekto al Database connection malsukcesis',\n",
            "    'code': 'DB_001',\n",
            "    'timestamp': '2024-03-20T10:30:00Z'\n",
            "}}\n",
            "\n",
            "Teknika noto: Ĉi tiu eraro okazas kiam la aplikaĵo ne povas konektiĝi al la datumbazo.\n",
            "\n",
            "Noto: Bonvolu konservi formalan tonon en la traduko.\n",
            "================================================================================\n",
            "\n",
            "=== Technical Translation in Spanish ===\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {{\n",
            "        'error': 'Database connection falló',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }}\n",
            "\n",
            "    Nota técnica: Este error ocurre cuando la aplicación no puede conectarse a la database.\n",
            "\n",
            "    \n",
            "    Nota: Por favor mantenga un tono formal en la traducción.\n",
            "    \n",
            "\n",
            "    \n",
            "    Keep the term \"DB_001\" unchanged in the translation.\n",
            "    \n",
            "    Keep the term \"Internal Server Error\" unchanged in the translation.\n",
            "    \n",
            "    Keep the term \"Database connection\" unchanged in the translation.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create few-shot examples for technical content formatting\n",
        "system_template = SystemMessagePromptTemplate.from_template(\n",
        "    \"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
        "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
        "\n",
        "    Example input and output pairs:\n",
        "\n",
        "    Input: \"Error 404: Page not found\"\n",
        "    Output: \"Error 404: Página no encontrada\"\n",
        "\n",
        "    Input: \"Status: 200 OK\n",
        "    Response: {% raw %}{{\n",
        "        'data': 'success',\n",
        "        'message': 'Operation completed'\n",
        "    }}{% endraw %}\"\n",
        "    Output: \"Status: 200 OK\n",
        "    Response: {% raw %}{{\n",
        "        'data': 'success',\n",
        "        'message': 'Operación completada'\n",
        "    }}{% endraw %}\"\n",
        "    \"\"\",\n",
        "    template_format=\"jinja2\"\n",
        ")\n",
        "\n",
        "# Example of a technical input using Jinja2's control structures and filters\n",
        "human_template = HumanMessagePromptTemplate.from_template(\n",
        "    \"\"\"Translate this technical information to {{ language|upper }}:\n",
        "\n",
        "    Status: 500 Internal Server Error\n",
        "    Response: {% raw %}{{\n",
        "        'error': 'Database connection failed',\n",
        "        'code': 'DB_001',\n",
        "        'timestamp': '2024-03-20T10:30:00Z'\n",
        "    }}{% endraw %}\n",
        "\n",
        "    Technical Note: This error occurs when the application cannot connect to the database.\n",
        "\n",
        "    {% if language == 'spanish' %}\n",
        "    Note: Please use formal Spanish for technical documentation.\n",
        "    {% elif language == 'french' %}\n",
        "    Note: Please use formal French for technical documentation.\n",
        "    {% else %}\n",
        "    Note: Please maintain a formal tone in the translation.\n",
        "    {% endif %}\n",
        "\n",
        "    {% for term in technical_terms %}\n",
        "    Keep the term \"{{ term }}\" unchanged in the translation.\n",
        "    {% endfor %}\n",
        "    \"\"\",\n",
        "    template_format=\"jinja2\"\n",
        ")\n",
        "\n",
        "# Create the chain using LCEL pipe syntax\n",
        "chain = (\n",
        "    ChatPromptTemplate.from_messages([system_template, human_template])\n",
        "    | chat\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Loop through each language\n",
        "for language in languages:\n",
        "    print(f\"\\n=== Technical Translation in {language} ===\")\n",
        "\n",
        "    # Invoke the chain with our inputs\n",
        "    result = chain.invoke({\n",
        "        \"language\": language,\n",
        "        \"technical_terms\": ['DB_001', 'Internal Server Error', 'Database connection']\n",
        "    })\n",
        "\n",
        "    print(result)\n",
        "    print(\"=\" * 80)  # Separator for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYNYCY0Fi_LL"
      },
      "source": [
        "Let's see what the prompts look like after LangChain interprets the Jinja2 templates. This demonstrates how LangChain automatically handles the template interpretation for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2P_BmPVi_LL",
        "outputId": "def1bc71-40ad-4c82-9c10-92172680b1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Formatted Prompt for Spanish ===\n",
            "\n",
            "SYSTEM MESSAGE:\n",
            "----------------------------------------\n",
            "You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
            "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
            "\n",
            "    Example input and output pairs:\n",
            "\n",
            "    Input: \"Error 404: Page not found\"\n",
            "    Output: \"Error 404: Página no encontrada\"\n",
            "\n",
            "    Input: \"Status: 200 OK\n",
            "    Response: {{\n",
            "        'data': 'success',\n",
            "        'message': 'Operation completed'\n",
            "    }}\"\n",
            "    Output: \"Status: 200 OK\n",
            "    Response: {{\n",
            "        'data': 'success',\n",
            "        'message': 'Operación completada'\n",
            "    }}\"\n",
            "    \n",
            "================================================================================\n",
            "\n",
            "HUMAN MESSAGE:\n",
            "----------------------------------------\n",
            "Translate this technical information to SPANISH:\n",
            "\n",
            "    Status: 500 Internal Server Error\n",
            "    Response: {{\n",
            "        'error': 'Database connection failed',\n",
            "        'code': 'DB_001',\n",
            "        'timestamp': '2024-03-20T10:30:00Z'\n",
            "    }}\n",
            "\n",
            "    Technical Note: This error occurs when the application cannot connect to the database.\n",
            "\n",
            "    \n",
            "    Note: Please use formal Spanish for technical documentation.\n",
            "    \n",
            "\n",
            "    \n",
            "    Keep the term \"DB_001\" unchanged in the translation.\n",
            "    \n",
            "    Keep the term \"Internal Server Error\" unchanged in the translation.\n",
            "    \n",
            "    Keep the term \"Database connection\" unchanged in the translation.\n",
            "    \n",
            "    \n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Get the formatted prompt for Spanish\n",
        "print(\"\\n=== Formatted Prompt for Spanish ===\")\n",
        "\n",
        "# Format the prompts with our inputs\n",
        "formatted_prompt = ChatPromptTemplate.from_messages([\n",
        "    system_template,\n",
        "    human_template\n",
        "]).format_prompt(\n",
        "    language='spanish',\n",
        "    technical_terms=['DB_001', 'Internal Server Error', 'Database connection']\n",
        ")\n",
        "\n",
        "# Print the formatted messages\n",
        "for message in formatted_prompt.to_messages():\n",
        "    print(f\"\\n{message.type.upper()} MESSAGE:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(message.content)\n",
        "    print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb4DmDPxi_LL"
      },
      "source": [
        "Let's break down how LangChain automatically interpreted the Jinja2 templates in our prompts:\n",
        "\n",
        "1. **Language Filter and Variable**:\n",
        "   - Original: `{{ language|upper }}`\n",
        "   - Interpreted as: `SPANISH`\n",
        "   - The `|upper` filter automatically converted the language to uppercase\n",
        "\n",
        "2. **Conditional Logic**:\n",
        "   - Original:\n",
        "     ```jinja2\n",
        "     {% if language == 'spanish' %}\n",
        "     Note: Please use formal Spanish for technical documentation.\n",
        "     {% elif language == 'french' %}\n",
        "     Note: Please use formal French for technical documentation.\n",
        "     {% else %}\n",
        "     Note: Please maintain a formal tone in the translation.\n",
        "     {% endif %}\n",
        "     ```\n",
        "   - Interpreted as: `Note: Please use formal Spanish for technical documentation.`\n",
        "   - The `if` statement automatically selected the Spanish-specific note\n",
        "\n",
        "3. **Loop Structure**:\n",
        "   - Original:\n",
        "     ```jinja2\n",
        "     {% for term in technical_terms %}\n",
        "     Keep the term \"{{ term }}\" unchanged in the translation.\n",
        "     {% endfor %}\n",
        "     ```\n",
        "   - Interpreted as three separate lines, one for each technical term:\n",
        "     ```\n",
        "     Keep the term \"DB_001\" unchanged in the translation.\n",
        "     Keep the term \"Internal Server Error\" unchanged in the translation.\n",
        "     Keep the term \"Database connection\" unchanged in the translation.\n",
        "     ```\n",
        "   - The `for` loop automatically iterated through our list of technical terms\n",
        "\n",
        "4. **Raw JSON Blocks**:\n",
        "   - Original: `{% raw %}{{ ... }}{% endraw %}`\n",
        "   - Interpreted as: `{{ ... }}`\n",
        "   - The `raw` tags were automatically removed while preserving the JSON structure"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "LangChain-Pinecone-io-thing (3.12.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
